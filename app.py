import streamlit as st
import sqlite3
import pandas as pd
import networkx as nx
from pyvis.network import Network
import tempfile
import os
from dotenv import load_dotenv

# LangChainé–¢é€£
from langchain_openai import ChatOpenAI
from langchain_classic.agents import create_react_agent, AgentExecutor
from langchain_classic.prompts import PromptTemplate
from langchain.tools import tool
from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_classic.chains import RetrievalQA

# ===============================
# .envãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")


st.set_page_config(page_title="ğŸ§  Smart Memo Agent", layout="wide")

if not openai_api_key:
    st.error("`.env` ã« OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

# LLMåˆæœŸåŒ–ï¼ˆAPIã‚­ãƒ¼ã¯å¼•æ•°ã§æ¸¡ã™ï¼‰
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3, openai_api_key=openai_api_key)

# ===============================
# åˆæœŸè¨­å®š
# ===============================
st.set_page_config(page_title="ğŸ§  Smart Memo Agent", layout="wide")

# .envèª­ã¿è¾¼ã¿
openai_api_key = os.getenv("OPENAI_API_KEY")

if not openai_api_key:
    st.error("`.env` ã« OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

# LLMåˆæœŸåŒ–
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3, openai_api_key=openai_api_key)

# ===============================
# SQLite DBæº–å‚™
# ===============================
conn = sqlite3.connect("memo.db")
c = conn.cursor()
c.execute('''CREATE TABLE IF NOT EXISTS memos (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                content TEXT,
                url TEXT,
                category TEXT
            )''')
conn.commit()

# ===============================
# ãƒ¡ãƒ¢ç™»éŒ²ãƒ•ã‚©ãƒ¼ãƒ 
# ===============================
st.header("ğŸ“ ãƒ¡ãƒ¢ãƒ»URL ç™»éŒ²")

with st.form("memo_form"):
    memo_text = st.text_area("ãƒ¡ãƒ¢å†…å®¹")
    memo_url = st.text_input("URLï¼ˆä»»æ„ï¼‰")
    submit_btn = st.form_submit_button("ç™»éŒ²")

    if submit_btn and memo_text:
        # è‡ªå‹•ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ï¼ˆLLMï¼‰
        category_prompt = f"""
        ä»¥ä¸‹ã®ãƒ¡ãƒ¢ã‚’ä¸»è¦ã‚«ãƒ†ã‚´ãƒªã®1ã¤ã«åˆ†é¡ã—ã¦ãã ã•ã„ã€‚
        å€™è£œ: å¥åº·, ä»•äº‹, å­¦ç¿’, äººé–“é–¢ä¿‚, æŠ•è³‡, è¶£å‘³, ãã®ä»–
        ãƒ¡ãƒ¢: {memo_text}
        å‡ºåŠ›ã¯ã‚«ãƒ†ã‚´ãƒªåã®ã¿ã€‚
        """
        cat = llm.invoke(category_prompt).content.strip()
        c.execute("INSERT INTO memos (content, url, category) VALUES (?, ?, ?)", (memo_text, memo_url, cat))
        conn.commit()
        st.success(f"âœ… ç™»éŒ²å®Œäº†ï¼ï¼ˆã‚«ãƒ†ã‚´ãƒª: {cat}ï¼‰")

# ===============================
# DBè¡¨ç¤º
# ===============================
st.subheader("ğŸ“‚ ç™»éŒ²æ¸ˆã¿ãƒ¡ãƒ¢")
df = pd.read_sql_query("SELECT * FROM memos", conn)
st.dataframe(df)

# ===============================
# é–¢ä¿‚æ€§ã‚°ãƒ©ãƒ•å¯è¦–åŒ–
# ===============================
st.subheader("ğŸ•¸ï¸ ãƒ¡ãƒ¢ã®é–¢ä¿‚æ€§ã‚°ãƒ©ãƒ•")

if not df.empty:
    G = nx.Graph()
    for _, row in df.iterrows():
        G.add_node(row["content"], title=row["category"])
        G.add_edge(row["category"], row["content"])

    net = Network(height="500px", bgcolor="#FFFFFF", directed=False)
    net.from_nx(G)
    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
        net.save_graph(tmp_file.name)
        st.components.v1.html(open(tmp_file.name, 'r', encoding='utf-8').read(), height=520)

# ===============================
# RAGï¼ˆRetrieval QAï¼‰
# ===============================
st.subheader("ğŸ¤– Agentã«è³ªå•")

if not df.empty:
    # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ä½œæˆ
    docs = [Document(page_content=row["content"], metadata={"category": row["category"]}) for _, row in df.iterrows()]
    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
    vectordb = FAISS.from_documents(docs, embeddings)
    retriever = vectordb.as_retriever()

    # QA Chainæ§‹ç¯‰
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,
        chain_type="stuff",
        return_source_documents=True,
    )

    # Toolå®šç¾©
    tools = [
        tool(
            name="KnowledgeBaseQA",
            func=qa_chain.run,
            description="ãƒ¡ãƒ¢DBã«åŸºã¥ãè³ªå•å¿œç­”ã‚’è¡Œã†ãƒ„ãƒ¼ãƒ«ã€‚ã‚«ãƒ†ã‚´ãƒªã‚„å†…å®¹ã®è¦ç´„ã€é–¢ä¿‚æ€§ãªã©ã‚’ç­”ãˆã‚‹ã€‚"
        )
    ]

    # Promptå®šç¾©ï¼ˆReActã‚¹ã‚¿ã‚¤ãƒ«ï¼‰
    react_prompt = PromptTemplate.from_template("""
    ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒ¢ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ç®¡ç†ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ã€ã‚«ãƒ†ã‚´ãƒªã‚„å†…å®¹ã‚’ç†è§£ã—ã€å¿…è¦ã«å¿œã˜ã¦KnowledgeBaseQAãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦ç­”ãˆã¦ãã ã•ã„ã€‚
    
    ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:
    Thought: ...
    Action: ...
    Action Input: ...
    Observation: ...
    Final Answer: ...
    
    Human: {input}
    """)

    # Agentä½œæˆ
    agent = create_react_agent(llm, tools, prompt=react_prompt)
    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

    # å…¥åŠ›æ¬„
    user_query = st.text_input("ğŸ’¬ Agentã«è³ªå•ï¼ˆä¾‹ï¼šã€Œå¥åº·ã‚«ãƒ†ã‚´ãƒªã®è¦ç´„ã‚’è¦‹ã›ã¦ã€ï¼‰")

    if st.button("é€ä¿¡") and user_query:
        with st.spinner("ğŸ¤” è€ƒãˆä¸­..."):
            response = agent_executor.invoke({"input": user_query})
            st.markdown("### ğŸ§© å›ç­”")
            st.success(response["output"])
else:
    st.info("ã¾ã ãƒ¡ãƒ¢ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

conn.close()
