import subprocess
import sys

subprocess.check_call([sys.executable, "-m", "pip", "install", "-r", "requirements.txt"])


import streamlit as st
import sqlite3
import pandas as pd
import networkx as nx
from pyvis.network import Network
import tempfile
import os
from dotenv import load_dotenv

# LangChainé–¢é€£
from langchain_openai import ChatOpenAI
from langchain_classic.agents import create_react_agent, AgentExecutor
from langchain_classic.prompts import PromptTemplate
from langchain_classic.tools import Tool
from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_classic.chains import RetrievalQA

# .envãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

st.set_page_config(page_title="ğŸ§  Smart Memo Agent", layout="wide")

if not openai_api_key:
    st.error("`.env` ã« OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

# LLMåˆæœŸåŒ–ï¼ˆAPIã‚­ãƒ¼ã¯å¼•æ•°ã§æ¸¡ã™ï¼‰
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3, openai_api_key=openai_api_key)

# DBæº–å‚™
conn = sqlite3.connect("memo.db")
c = conn.cursor()
c.execute('''
CREATE TABLE IF NOT EXISTS memos (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    content TEXT,
    url TEXT,
    category TEXT
)''')
conn.commit()

st.header("ğŸ“ ãƒ¡ãƒ¢ãƒ»URL ç™»éŒ²")

# æ—¢å­˜ã‚«ãƒ†ã‚´ãƒªã®èª­ã¿è¾¼ã¿ï¼ˆDBã‹å›ºå®šãƒªã‚¹ãƒˆï¼‰
default_categories = ["é£Ÿã¹ç‰©", "ä»•äº‹", "AIå‹‰å¼·", "è³‡æ ¼", "ãƒ€ãƒ³ã‚¹", "æ—¥è¨˜", "ãŠé‡‘", "èªå­¦å‹‰å¼·", "ãã®ä»–"]

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã‚«ãƒ†ã‚´ãƒªã®è‡ªç”±ç·¨é›†
st.sidebar.subheader("ã‚«ãƒ†ã‚´ãƒªç®¡ç†")
new_category = st.sidebar.text_input("æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªã‚’è¿½åŠ ")
if st.sidebar.button("ã‚«ãƒ†ã‚´ãƒªè¿½åŠ ") and new_category:
    default_categories.append(new_category)
    st.sidebar.success(f"ã‚«ãƒ†ã‚´ãƒª '{new_category}' ã‚’è¿½åŠ ã—ã¾ã—ãŸï¼")

with st.form("memo_form"):
    memo_text = st.text_area("ãƒ¡ãƒ¢å†…å®¹")
    memo_url = st.text_input("URLï¼ˆä»»æ„ï¼‰")
    selected_category = st.selectbox("ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠï¼ˆè‡ªå‹•åˆ†é¡ã‚‚å¯ï¼‰", ["è‡ªå‹•åˆ†é¡"] + default_categories)
    submit_btn = st.form_submit_button("ç™»éŒ²")

    if submit_btn and memo_text:
        if selected_category == "è‡ªå‹•åˆ†é¡":
            # ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            category_prompt = f"""
ä»¥ä¸‹ã®ãƒ¡ãƒ¢ã‚’ä¸»è¦ã‚«ãƒ†ã‚´ãƒªã®1ã¤ã«åˆ†é¡ã—ã¦ãã ã•ã„ã€‚
å€™è£œ: {', '.join(default_categories)}
ãƒ¡ãƒ¢: {memo_text}
å‡ºåŠ›ã¯ã‚«ãƒ†ã‚´ãƒªåã®ã¿ã€‚
"""
            cat = llm.invoke(category_prompt).content.strip()
        else:
            cat = selected_category

        c.execute(
            "INSERT INTO memos (content, url, category) VALUES (?, ?, ?)",
            (memo_text, memo_url, cat)
        )
        conn.commit()
        st.success(f"ç™»éŒ²å®Œäº†ï¼ï¼ˆã‚«ãƒ†ã‚´ãƒª: {cat}ï¼‰")

st.subheader("ç™»éŒ²æ¸ˆã¿ãƒ¡ãƒ¢")
df = pd.read_sql_query("SELECT * FROM memos", conn)
st.dataframe(df)

st.subheader("ğŸ—‘ï¸ ãƒ¡ãƒ¢ã®å‰Šé™¤")

# DBã‹ã‚‰ãƒ¡ãƒ¢ã‚’å–å¾—
df = pd.read_sql_query("SELECT * FROM memos", conn)

# multiselectã§å‰Šé™¤å¯¾è±¡ã‚’é¸æŠ
to_delete = st.multiselect(
    "å‰Šé™¤ã™ã‚‹ãƒ¡ãƒ¢ã‚’é¸æŠ",
    options=df["id"].tolist(),
    format_func=lambda x: df[df["id"] == x]["content"].values[0]
)

if st.button("å‰Šé™¤"):
    if to_delete:
        c.executemany("DELETE FROM memos WHERE id=?", [(i,) for i in to_delete])
        conn.commit()
        st.success(f"{len(to_delete)}ä»¶ã®ãƒ¡ãƒ¢ã‚’å‰Šé™¤ã—ã¾ã—ãŸï¼")
    else:
        st.warning("å‰Šé™¤ã™ã‚‹ãƒ¡ãƒ¢ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")

st.subheader("ğŸ•¸ï¸ ãƒ¡ãƒ¢ã®é–¢ä¿‚æ€§ã‚°ãƒ©ãƒ•")

if not df.empty:
    G = nx.Graph()
    for _, row in df.iterrows():
        G.add_node(row["content"][:40], title=f"Category: {row['category']}")  # é•·éãã‚‹å ´åˆã‚«ãƒƒãƒˆ
        G.add_edge(row["category"], row["content"][:40])

    net = Network(height="500px", bgcolor="#FFFFFF", directed=False)
    net.from_nx(G)

    with tempfile.NamedTemporaryFile(delete=False, suffix=".html") as tmp_file:
        net.save_graph(tmp_file.name)
        tmp_file_path = tmp_file.name

    with open(tmp_file_path, 'r', encoding='utf-8') as f:
        html_content = f.read()
    st.components.v1.html(html_content, height=520)

st.subheader("ğŸ¤– Agentã«è³ªå•")

if not df.empty:
    docs = [Document(page_content=row["content"], metadata={"category": row["category"]}) for _, row in df.iterrows()]
    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
    vectordb = FAISS.from_documents(docs, embeddings)
    retriever = vectordb.as_retriever()

    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,
        chain_type="stuff",
        return_source_documents=True,
    )

    tools = [
        Tool(
            name="KnowledgeBaseQA",
            func=qa_chain.run,
            description="ãƒ¡ãƒ¢DBã«åŸºã¥ãè³ªå•å¿œç­”ã‚’è¡Œã†ãƒ„ãƒ¼ãƒ«ã€‚ã‚«ãƒ†ã‚´ãƒªã‚„å†…å®¹ã®è¦ç´„ã€é–¢ä¿‚æ€§ãªã©ã‚’ç­”ãˆã‚‹ã€‚"
        )
    ]

    react_prompt = PromptTemplate(
    template="""
ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒ¢ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ç®¡ç†ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹éš›ã¯ã€ä»¥ä¸‹ã®æ‰‹é †ã§è€ƒãˆã¦ãã ã•ã„ï¼š

1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’ã‚«ãƒ†ã‚´ãƒªã‚„å†…å®¹ã«åŸºã¥ã„ã¦ç†è§£
2. é–¢é€£ã™ã‚‹ãƒ¡ãƒ¢ã‚’KnowledgeBaseQAãƒ„ãƒ¼ãƒ«ã§æ¤œç´¢
3. ã‚µãƒãƒªãƒ¼ã‚„è¦ç‚¹ã‚’æ•´ç†ã—ã€åˆ†ã‹ã‚Šã‚„ã™ãå‡ºåŠ›
4. å¿…è¦ã«å¿œã˜ã¦ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆActionï¼‰ã¨ã—ã¦ãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã™
5. æœ€çµ‚å›ç­”ï¼ˆFinal Answerï¼‰ã¨ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ä¼ãˆã‚‹

ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:
Thought: ä»Šè€ƒãˆã¦ã„ã‚‹ã“ã¨ã‚„æ¨è«–
Action: ä½¿ã†ãƒ„ãƒ¼ãƒ«åï¼ˆå¿…è¦ãªå ´åˆï¼‰
Action Input: ãƒ„ãƒ¼ãƒ«ã«æ¸¡ã™å…¥åŠ›
Observation: ãƒ„ãƒ¼ãƒ«ã®å‡ºåŠ›çµæœ
Final Answer: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®æœ€çµ‚å›ç­”

{agent_scratchpad}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {input}
åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«: {tools}
ãƒ„ãƒ¼ãƒ«åä¸€è¦§: {tool_names}
""",
    input_variables=["input", "agent_scratchpad", "tools", "tool_names"]
)

    agent = create_react_agent(llm, tools, prompt=react_prompt)
    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

    user_query = st.text_input("Agentã«è³ªå•ï¼ˆä¾‹ï¼šã€Œå¥åº·ã‚«ãƒ†ã‚´ãƒªã®è¦ç´„ã‚’è¦‹ã›ã¦ã€ï¼‰")

    if st.button("é€ä¿¡") and user_query:
        with st.spinner("è€ƒãˆä¸­..."):
            response = agent_executor.invoke({"input": user_query})
            st.markdown("### å›ç­”")
            st.success(response["output"])
else:
    st.info("ã¾ã ãƒ¡ãƒ¢ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

conn.close()
