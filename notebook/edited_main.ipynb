{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e8692a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/woojoohyeon/Desktop/memo_categorizing/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# app.py\n",
    "import os\n",
    "import sqlite3\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import streamlit.components.v1 as components\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM, AutoModel\n",
    "import torch\n",
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4595dff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.agents import AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a963d2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain imports (agentä½œæˆç”¨)\n",
    "from langchain.agents import create_agent\n",
    "from langchain_classic.agents import create_react_agent, Tool\n",
    "#from langchain.tools import tool\n",
    "from langchain_classic.agents import AgentExecutor\n",
    "# Note: HuggingFacePipeline wrapper for LangChain LLM\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "\n",
    "# Embeddings via sentence-transformers (we'll use HF wrapper)\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18fee7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9w/b6hfk5hx24bfj8s1bys2b6bh0000gn/T/ipykernel_20168/2633226407.py:8: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEndpoint``.\n",
      "  llm = HuggingFaceHub(repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\")\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for HuggingFaceHub\n  Value error, Did not find huggingfacehub_api_token, please add an environment variable `HUGGINGFACEHUB_API_TOKEN` which contains it, or pass `huggingfacehub_api_token` as a named parameter. [type=value_error, input_value={'repo_id': 'mistralai/Mi...acehub_api_token': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceHub\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbeddings\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m llm = \u001b[43mHuggingFaceHub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmistralai/Mistral-7B-Instruct-v0.2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m embeddings = HuggingFaceEmbeddings(model_name=\u001b[33m\"\u001b[39m\u001b[33msentence-transformers/all-MiniLM-L6-v2\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m DB_PATH = \u001b[33m\"\u001b[39m\u001b[33mmemos.db\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/memo_categorizing/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:221\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    219\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    220\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/memo_categorizing/.venv/lib/python3.12/site-packages/langchain_core/load/serializable.py:116\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    115\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419  # Intentional blank docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/memo_categorizing/.venv/lib/python3.12/site-packages/pydantic/main.py:250\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    249\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    252\u001b[39m     warnings.warn(\n\u001b[32m    253\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    254\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    256\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    257\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for HuggingFaceHub\n  Value error, Did not find huggingfacehub_api_token, please add an environment variable `HUGGINGFACEHUB_API_TOKEN` which contains it, or pass `huggingfacehub_api_token` as a named parameter. [type=value_error, input_value={'repo_id': 'mistralai/Mi...acehub_api_token': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/value_error"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# --- è¨­å®šãƒ»ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ ---\n",
    "# ---------------------------\n",
    "\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "llm = HuggingFaceHub(repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "DB_PATH = \"memos.db\"\n",
    "FAISS_INDEX_PATH = \"faiss.index\"\n",
    "EMBEDDING_DIM = 384  # all-MiniLM-L6-v2 ã®æ¬¡å…ƒ\n",
    "EMBED_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "LLM_MODEL_NAME = \"google/flan-t5-small\"  # å°å‹ã®FLAN-T5ã€‚é‡ã„ãªã‚‰ã•ã‚‰ã«å°ã•ã„ã‚‚ã®ã«å¤‰æ›´å¯\n",
    "SUMMARIZER_MODEL = LLM_MODEL_NAME  # å†åˆ©ç”¨\n",
    "ZERO_SHOT_MODEL = \"facebook/bart-large-mnli\"  # ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30c3a6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# --- DB ãƒ˜ãƒ«ãƒ‘ãƒ¼ ---\n",
    "# ---------------------------\n",
    "def init_db():\n",
    "    conn = sqlite3.connect(DB_PATH, check_same_thread=False)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\n",
    "        \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS memos (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            text TEXT,\n",
    "            url TEXT,\n",
    "            category TEXT,\n",
    "            summary TEXT,\n",
    "            created_at REAL\n",
    "        )\n",
    "        \"\"\"\n",
    "    )\n",
    "    conn.commit()\n",
    "    return conn\n",
    "\n",
    "conn = init_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bb1f8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# --- Embedding & FAISS ---\n",
    "# ---------------------------\n",
    "@st.cache_resource\n",
    "def load_embedding_model():\n",
    "    return SentenceTransformer(EMBED_MODEL_NAME)\n",
    "\n",
    "@st.cache_resource\n",
    "def load_zero_shot():\n",
    "    return pipeline(\"zero-shot-classification\", model=ZERO_SHOT_MODEL)\n",
    "\n",
    "@st.cache_resource\n",
    "def load_summarizer_pipeline():\n",
    "    # HF seq2seq pipeline for summarization / text2text\n",
    "    tokenizer = AutoTokenizer.from_pretrained(SUMMARIZER_MODEL)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(SUMMARIZER_MODEL)\n",
    "    # Use LangChain HuggingFacePipeline wrapper later\n",
    "    summarizer = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "    return summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a92bdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.cache_resource\n",
    "def load_llm_for_langchain():\n",
    "    # Prepare a transformers pipeline and wrap with LangChain's HuggingFacePipeline\n",
    "    tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL_NAME)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(LLM_MODEL_NAME)\n",
    "    hf_pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "    return HuggingFacePipeline(pipeline=hf_pipe)\n",
    "\n",
    "def build_faiss_index(embeddings: np.ndarray):\n",
    "    index = faiss.IndexFlatL2(EMBEDDING_DIM)\n",
    "    index.add(embeddings)\n",
    "    return index\n",
    "\n",
    "def save_faiss(index: faiss.IndexFlatL2):\n",
    "    faiss.write_index(index, FAISS_INDEX_PATH)\n",
    "\n",
    "def load_faiss():\n",
    "    if os.path.exists(FAISS_INDEX_PATH):\n",
    "        return faiss.read_index(FAISS_INDEX_PATH)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "141ca5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# --- DB æ“ä½œé–¢æ•° ---\n",
    "# ---------------------------\n",
    "def insert_memo(text: str, url: str, category: str = None, summary: str = None):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\n",
    "        \"INSERT INTO memos (text, url, category, summary, created_at) VALUES (?, ?, ?, ?, ?)\",\n",
    "        (text, url, category, summary, time.time()),\n",
    "    )\n",
    "    conn.commit()\n",
    "    return cur.lastrowid\n",
    "\n",
    "def update_memo(id_: int, **kwargs):\n",
    "    cur = conn.cursor()\n",
    "    set_clause = \", \".join([f\"{k} = ?\" for k in kwargs.keys()])\n",
    "    values = list(kwargs.values())\n",
    "    values.append(id_)\n",
    "    cur.execute(f\"UPDATE memos SET {set_clause} WHERE id = ?\", values)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58d98c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_memo(id_: int):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"DELETE FROM memos WHERE id = ?\", (id_,))\n",
    "    conn.commit()\n",
    "\n",
    "def list_memos() -> pd.DataFrame:\n",
    "    df = pd.read_sql_query(\"SELECT * FROM memos ORDER BY created_at DESC\", conn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94c83624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# --- RAG ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ---\n",
    "# ---------------------------\n",
    "@st.cache_resource\n",
    "def get_emb_model():\n",
    "    return load_embedding_model()\n",
    "\n",
    "def build_embeddings_for_all():\n",
    "    df = list_memos()\n",
    "    if df.empty:\n",
    "        return np.zeros((0, EMBEDDING_DIM), dtype=\"float32\")\n",
    "    texts = (df[\"text\"].fillna(\"\") + \" \" + df[\"url\"].fillna(\"\")).tolist()\n",
    "    emb_model = get_emb_model()\n",
    "    embs = emb_model.encode(texts, convert_to_numpy=True, show_progress_bar=False)\n",
    "    # ensure float32\n",
    "    return embs.astype(\"float32\")\n",
    "\n",
    "def rebuild_faiss_from_db():\n",
    "    embs = build_embeddings_for_all()\n",
    "    if embs.shape[0] == 0:\n",
    "        return None\n",
    "    index = build_faiss_index(embs)\n",
    "    save_faiss(index)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8e99db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_text_to_faiss(text: str, index: faiss.IndexFlatL2):\n",
    "    emb_model = get_emb_model()\n",
    "    emb = emb_model.encode([text], convert_to_numpy=True).astype(\"float32\")\n",
    "    index.add(emb)\n",
    "    save_faiss(index)\n",
    "\n",
    "def retrieve_similar(text: str, k: int = 3):\n",
    "    index = load_faiss()\n",
    "    if index is None:\n",
    "        return []\n",
    "    emb_model = get_emb_model()\n",
    "    q = emb_model.encode([text], convert_to_numpy=True).astype(\"float32\")\n",
    "    D, I = index.search(q, k)\n",
    "    ids = I[0].tolist()\n",
    "    # map index positions to DB rows (assume ordering same as SELECT by created_at DESC)\n",
    "    df = list_memos()\n",
    "    if df.empty:\n",
    "        return []\n",
    "    # If FAISS index built from all rows in order, indices match df.index\n",
    "    # To be safe: clip indices\n",
    "    docs = []\n",
    "    for idx in ids:\n",
    "        if idx < len(df):\n",
    "            row = df.iloc[idx]\n",
    "            docs.append({\"id\": int(row[\"id\"]), \"text\": row[\"text\"], \"url\": row[\"url\"], \"category\": row[\"category\"], \"summary\": row[\"summary\"]})\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6bcf05af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# --- Agent ç”¨ãƒ„ãƒ¼ãƒ« ---\n",
    "# ---------------------------\n",
    "def memo_search_tool(query: str) -> str:\n",
    "    # retrieve top-k memos and return readable text\n",
    "    docs = retrieve_similar(query, k=5)\n",
    "    if len(docs) == 0:\n",
    "        return \"è©²å½“ã™ã‚‹ãƒ¡ãƒ¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\"\n",
    "    out = []\n",
    "    for d in docs:\n",
    "        s = f\"[id:{d['id']}] category:{d.get('category')}\\n{d['text']}\\nURL: {d.get('url')}\\n---\"\n",
    "        out.append(s)\n",
    "    return \"\\n\".join(out)\n",
    "\n",
    "def memo_list_by_category_tool(category_q: str) -> str:\n",
    "    df = list_memos()\n",
    "    if df.empty:\n",
    "        return \"ãƒ¡ãƒ¢ã¯ã¾ã ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\"\n",
    "    filtered = df[df[\"category\"] == category_q]\n",
    "    if filtered.empty:\n",
    "        return f\"ã‚«ãƒ†ã‚´ãƒª '{category_q}' ã®ãƒ¡ãƒ¢ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\"\n",
    "    texts = []\n",
    "    for _, r in filtered.iterrows():\n",
    "        texts.append(f\"[id:{r['id']}] {r['text']}\")\n",
    "    return \"\\n\".join(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "553194bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# --- Build Agent (create_react_agent + AgentExecutor) ---\n",
    "# ---------------------------\n",
    "@st.cache_resource\n",
    "def build_agent_executor():\n",
    "    llm = load_llm_for_langchain()\n",
    "    # Tools: search by semantic similarity, list-by-category\n",
    "    tools = [\n",
    "        Tool(name=\"MemoSearch\", func=memo_search_tool, description=\"ãƒ¡ãƒ¢DBã‹ã‚‰é–¢é€£ã™ã‚‹ãƒ¡ãƒ¢ã‚’è¿”ã™ï¼ˆå…¨æ–‡ï¼‰\"),\n",
    "        Tool(name=\"ListByCategory\", func=memo_list_by_category_tool, description=\"ã‚«ãƒ†ã‚´ãƒªåã‚’å—ã‘å–ã‚Šã€ãã®ã‚«ãƒ†ã‚´ãƒªã®ãƒ¡ãƒ¢ä¸€è¦§ã‚’è¿”ã™\"),\n",
    "    ]\n",
    "    # create_react_agent returns a callable agent; wrap with AgentExecutor\n",
    "    agent = create_react_agent(llm=llm, tools=tools)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools, verbose=False)\n",
    "    return executor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e992dd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# --- Summarizer using HF pipeline (FLAN-T5) ---\n",
    "# ---------------------------\n",
    "@st.cache_resource\n",
    "def get_summarizer():\n",
    "    return load_summarizer_pipeline()\n",
    "\n",
    "def summarize_texts(texts: List[str], max_length: int = 150):\n",
    "    summarizer = get_summarizer()\n",
    "    joined = \"\\n\".join(texts)\n",
    "    # make short prompt to ask summarization\n",
    "    prompt = \"æ¬¡ã®ãƒ¡ãƒ¢ã‚’è¦ç´„ã—ã¦çŸ­ã„æ—¥æœ¬èªã®è¦ç´„ã‚’1ã¤ä½œã£ã¦ãã ã•ã„:\\n\\n\" + joined\n",
    "    out = summarizer(prompt, max_length=max_length, do_sample=False, truncation=True)\n",
    "    # pipeline returns list of dicts\n",
    "    if isinstance(out, list) and len(out) > 0:\n",
    "        return out[0][\"generated_text\"]\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a4bab456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# --- Graph Visualization ---\n",
    "# ---------------------------\n",
    "def build_relation_graph_html(df: pd.DataFrame):\n",
    "    G = nx.Graph()\n",
    "    # add category nodes and memo nodes\n",
    "    for _, r in df.iterrows():\n",
    "        node_id_memo = f\"memo_{int(r['id'])}\"\n",
    "        G.add_node(node_id_memo, label=r[\"text\"][:40], title=r[\"text\"])\n",
    "        cat = r[\"category\"] if r[\"category\"] else \"æœªåˆ†é¡\"\n",
    "        node_id_cat = f\"cat_{cat}\"\n",
    "        if not G.has_node(node_id_cat):\n",
    "            G.add_node(node_id_cat, label=str(cat), title=str(cat), color=\"#FFD580\")\n",
    "        G.add_edge(node_id_cat, node_id_memo)\n",
    "    net = Network(height=\"600px\", width=\"100%\", notebook=False)\n",
    "    net.from_nx(G)\n",
    "    # physics for better layout\n",
    "    net.toggle_physics(True)\n",
    "    return net.generate_html(notebook=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4da6e9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 16:02:18.605 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.607 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.608 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.609 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.611 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.612 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.613 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.614 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.614 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.615 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.615 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.617 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.618 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.619 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.620 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.622 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.623 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.624 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.625 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.626 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.627 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.628 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.629 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.630 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.631 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.631 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.631 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.632 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.632 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.632 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.633 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.633 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.633 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.634 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.635 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.635 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.636 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.686 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.687 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.688 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.688 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.689 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.689 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.690 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.690 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.690 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.691 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.691 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.692 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.694 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.695 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.695 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:18.695 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:19.199 Thread 'Thread-22': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:19.202 Thread 'Thread-22': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:19.203 Thread 'Thread-22': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "Device set to use cpu\n",
      "/var/folders/9w/b6hfk5hx24bfj8s1bys2b6bh0000gn/T/ipykernel_20168/3529363384.py:7: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFacePipeline``.\n",
      "  return HuggingFacePipeline(pipeline=hf_pipe)\n",
      "2025-11-02 16:02:27.705 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:27.705 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-02 16:02:27.705 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "create_react_agent() missing 1 required positional argument: 'prompt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 77\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Agent è³ªå•ã‚¨ãƒªã‚¢\u001b[39;00m\n\u001b[32m     76\u001b[39m st.subheader(\u001b[33m\"\u001b[39m\u001b[33mğŸ¤– Agent ã«è‡ªç„¶è¨€èªã§è³ªå•\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m agent_executor = \u001b[43mbuild_agent_executor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m query = st.text_input(\u001b[33m\"\u001b[39m\u001b[33mä¾‹ï¼š\u001b[39m\u001b[33m'\u001b[39m\u001b[33må¥åº·ã‚«ãƒ†ã‚´ãƒªã®è¦ç´„ã‚’è¦‹ã›ã¦\u001b[39m\u001b[33m'\u001b[39m\u001b[33m / \u001b[39m\u001b[33m'\u001b[39m\u001b[33mæ—…è¡Œã«é–¢ã™ã‚‹ãƒ¡ãƒ¢ã‚’æ•™ãˆã¦\u001b[39m\u001b[33m'\u001b[39m\u001b[33m etc.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m st.button(\u001b[33m\"\u001b[39m\u001b[33mAgent å®Ÿè¡Œ\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/memo_categorizing/.venv/lib/python3.12/site-packages/streamlit/runtime/caching/cache_utils.py:228\u001b[39m, in \u001b[36mCachedFunc.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    225\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    226\u001b[39m         spinner_message = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m(...)`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_or_create_cached_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspinner_message\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/memo_categorizing/.venv/lib/python3.12/site-packages/streamlit/runtime/caching/cache_utils.py:270\u001b[39m, in \u001b[36mCachedFunc._get_or_create_cached_value\u001b[39m\u001b[34m(self, func_args, func_kwargs, spinner_message)\u001b[39m\n\u001b[32m    264\u001b[39m spinner_or_no_context = (\n\u001b[32m    265\u001b[39m     spinner(spinner_message, _cache=\u001b[38;5;28;01mTrue\u001b[39;00m, show_time=\u001b[38;5;28mself\u001b[39m._info.show_time)\n\u001b[32m    266\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m spinner_message \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_nested_cache_function\n\u001b[32m    267\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext()\n\u001b[32m    268\u001b[39m )\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m spinner_or_no_context:\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_cache_miss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/memo_categorizing/.venv/lib/python3.12/site-packages/streamlit/runtime/caching/cache_utils.py:329\u001b[39m, in \u001b[36mCachedFunc._handle_cache_miss\u001b[39m\u001b[34m(self, cache, value_key, func_args, func_kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;66;03m# We acquired the lock before any other thread. Compute the value!\u001b[39;00m\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._info.cached_message_replay_ctx.calling_cached_function(\n\u001b[32m    327\u001b[39m     \u001b[38;5;28mself\u001b[39m._info.func\n\u001b[32m    328\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m     computed_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[38;5;66;03m# We've computed our value, and now we need to write it back to the cache\u001b[39;00m\n\u001b[32m    332\u001b[39m \u001b[38;5;66;03m# along with any \"replay messages\" that were generated during value computation.\u001b[39;00m\n\u001b[32m    333\u001b[39m messages = \u001b[38;5;28mself\u001b[39m._info.cached_message_replay_ctx._most_recent_messages\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mbuild_agent_executor\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      8\u001b[39m tools = [\n\u001b[32m      9\u001b[39m     Tool(name=\u001b[33m\"\u001b[39m\u001b[33mMemoSearch\u001b[39m\u001b[33m\"\u001b[39m, func=memo_search_tool, description=\u001b[33m\"\u001b[39m\u001b[33mãƒ¡ãƒ¢DBã‹ã‚‰é–¢é€£ã™ã‚‹ãƒ¡ãƒ¢ã‚’è¿”ã™ï¼ˆå…¨æ–‡ï¼‰\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     10\u001b[39m     Tool(name=\u001b[33m\"\u001b[39m\u001b[33mListByCategory\u001b[39m\u001b[33m\"\u001b[39m, func=memo_list_by_category_tool, description=\u001b[33m\"\u001b[39m\u001b[33mã‚«ãƒ†ã‚´ãƒªåã‚’å—ã‘å–ã‚Šã€ãã®ã‚«ãƒ†ã‚´ãƒªã®ãƒ¡ãƒ¢ä¸€è¦§ã‚’è¿”ã™\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     11\u001b[39m ]\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# create_react_agent returns a callable agent; wrap with AgentExecutor\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m agent = \u001b[43mcreate_react_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m executor = AgentExecutor(agent=agent, tools=tools, verbose=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m executor\n",
      "\u001b[31mTypeError\u001b[39m: create_react_agent() missing 1 required positional argument: 'prompt'"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# --- Streamlit UI ---\n",
    "# ---------------------------\n",
    "st.set_page_config(page_title=\"RAG Memo Dashboard (local)\", layout=\"wide\")\n",
    "st.title(\"ğŸ§­ RAG + Agent ãƒ¡ãƒ¢ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰\")\n",
    "\n",
    "# Sidebar: å…¥åŠ›\n",
    "st.sidebar.header(\"âœï¸ æ–°è¦ãƒ¡ãƒ¢ç™»éŒ²\")\n",
    "memo_text = st.sidebar.text_area(\"ãƒ¡ãƒ¢æœ¬æ–‡ï¼ˆãƒ†ã‚­ã‚¹ãƒˆï¼‰\", height=120)\n",
    "memo_url = st.sidebar.text_input(\"é–¢é€£ URLï¼ˆä»»æ„ï¼‰\")\n",
    "# Category selection optional\n",
    "default_categories = [\"ä»•äº‹\", \"å‹‰å¼·\", \"å¥åº·\", \"æ„Ÿæƒ…\", \"ç”Ÿæ´»\", \"æ—…è¡Œ\", \"ãã®ä»–\"]\n",
    "selected_cat = st.sidebar.selectbox(\"ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠï¼ˆè‡ªå‹•åˆ†é¡ã—ãŸã„å ´åˆã¯ç©ºæ¬„ã§OKï¼‰\", [\"\"] + default_categories)\n",
    "\n",
    "if st.sidebar.button(\"ç™»éŒ²\"):\n",
    "    text = memo_text.strip()\n",
    "    if not text:\n",
    "        st.sidebar.warning(\"ãƒ¡ãƒ¢æœ¬æ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚\")\n",
    "    else:\n",
    "        # è‡ªå‹•ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ if not provided\n",
    "        category = selected_cat if selected_cat else None\n",
    "        if category is None:\n",
    "            zero_shot = load_zero_shot()\n",
    "            res = zero_shot(text, candidate_labels=default_categories)\n",
    "            category = res[\"labels\"][0]\n",
    "        # initial summary generate\n",
    "        summary = summarize_texts([text])[:500]\n",
    "        new_id = insert_memo(text=text, url=memo_url, category=category, summary=summary)\n",
    "        # rebuild/add to FAISS\n",
    "        index = load_faiss()\n",
    "        if index is None:\n",
    "            # rebuild whole from DB\n",
    "            index = rebuild_faiss_from_db()\n",
    "        else:\n",
    "            add_text_to_faiss(text, index)\n",
    "        st.sidebar.success(f\"ãƒ¡ãƒ¢ã‚’ç™»éŒ²ã—ã¾ã—ãŸï¼ˆid={new_id}ã€ã‚«ãƒ†ã‚´ãƒª={category}ï¼‰\")\n",
    "\n",
    "# Main area: show memos table\n",
    "st.subheader(\"ğŸ“š ç™»éŒ²æ¸ˆã¿ãƒ¡ãƒ¢\")\n",
    "df = list_memos()\n",
    "if df.empty:\n",
    "    st.info(\"ã¾ã ãƒ¡ãƒ¢ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰è¿½åŠ ã—ã¦ãã ã•ã„ã€‚\")\n",
    "else:\n",
    "    # display table with edit / delete options via streamlit elements\n",
    "    # Simple: show dataframe and allow id-based deletion\n",
    "    st.dataframe(df[[\"id\", \"text\", \"url\", \"category\", \"summary\", \"created_at\"]])\n",
    "\n",
    "    # delete by id\n",
    "    st.write(\"----\")\n",
    "    col1, col2 = st.columns([1, 3])\n",
    "    with col1:\n",
    "        del_id = st.number_input(\"å‰Šé™¤ã™ã‚‹ãƒ¡ãƒ¢IDã‚’å…¥åŠ›\", min_value=0, step=1)\n",
    "        if st.button(\"å‰Šé™¤\"):\n",
    "            if del_id > 0:\n",
    "                delete_memo(int(del_id))\n",
    "                # rebuild faiss\n",
    "                rebuild_faiss_from_db()\n",
    "                st.experimental_rerun()\n",
    "    with col2:\n",
    "        if st.button(\"ã‚«ãƒ†ã‚´ãƒªæ›´æ–°ï¼ˆè‡ªå‹•å†åˆ†é¡ï¼‰\"):\n",
    "            # re-run zero-shot for all memos without category or to refresh\n",
    "            zero_shot = load_zero_shot()\n",
    "            for _, r in df.iterrows():\n",
    "                text = r[\"text\"]\n",
    "                res = zero_shot(text, candidate_labels=default_categories)\n",
    "                update_memo(int(r[\"id\"]), category=res[\"labels\"][0])\n",
    "            st.success(\"å…¨ãƒ¡ãƒ¢ã®ã‚«ãƒ†ã‚´ãƒªã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚\")\n",
    "            st.experimental_rerun()\n",
    "\n",
    "# Graph visualization\n",
    "st.subheader(\"ğŸ”— é–¢ä¿‚æ€§ã‚°ãƒ©ãƒ•ï¼ˆã‚«ãƒ†ã‚´ãƒª - ãƒ¡ãƒ¢ï¼‰\")\n",
    "html = build_relation_graph_html(df) if not df.empty else \"<p>ãƒ¡ãƒ¢ãŒã‚ã‚Šã¾ã›ã‚“</p>\"\n",
    "components.html(html, height=650, scrolling=True)\n",
    "\n",
    "# Agent è³ªå•ã‚¨ãƒªã‚¢\n",
    "st.subheader(\"ğŸ¤– Agent ã«è‡ªç„¶è¨€èªã§è³ªå•\")\n",
    "agent_executor = build_agent_executor()\n",
    "query = st.text_input(\"ä¾‹ï¼š'å¥åº·ã‚«ãƒ†ã‚´ãƒªã®è¦ç´„ã‚’è¦‹ã›ã¦' / 'æ—…è¡Œã«é–¢ã™ã‚‹ãƒ¡ãƒ¢ã‚’æ•™ãˆã¦' etc.\")\n",
    "if st.button(\"Agent å®Ÿè¡Œ\"):\n",
    "    if not query.strip():\n",
    "        st.warning(\"è³ªå•æ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚\")\n",
    "    else:\n",
    "        # run agent; AgentExecutor may have invoke() or run()\n",
    "        try:\n",
    "            result = agent_executor.invoke({\"input\": query})\n",
    "            # result may be dict-like with \"output\"\n",
    "            if isinstance(result, dict) and \"output\" in result:\n",
    "                output_text = result[\"output\"]\n",
    "            else:\n",
    "                output_text = str(result)\n",
    "        except Exception:\n",
    "            try:\n",
    "                output_text = agent_executor.run(query)\n",
    "            except Exception as e:\n",
    "                output_text = f\"Agent å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\"\n",
    "        st.write(\"### âœ… Agent ã®å¿œç­”\")\n",
    "        # If the agent used MemoSearch tool, it will return memos. Now run summarizer on returned memos if needed.\n",
    "        st.write(output_text)\n",
    "        # Post-process: if output contains many memos, ask summarizer\n",
    "        if \"category\" in output_text or \"id:\" in output_text:\n",
    "            # crude extraction of texts - for demo, summarize top-k similar to query\n",
    "            docs = retrieve_similar(query, k=5)\n",
    "            if docs:\n",
    "                summary = summarize_texts([d[\"text\"] for d in docs])\n",
    "                st.write(\"### ğŸ” ãã®å†…å®¹ã®è¦ç´„ï¼ˆRAG â†’ Summarizeï¼‰\")\n",
    "                st.write(summary)\n",
    "\n",
    "# Footer / tips\n",
    "st.write(\"---\")\n",
    "st.caption(\"âš ï¸ æ³¨æ„: ã“ã®ã‚¢ãƒ—ãƒªã¯ãƒ­ãƒ¼ã‚«ãƒ«ã§å‹•ãç°¡æ˜“ãƒ‡ãƒ¢ã§ã™ã€‚å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚„é«˜é »åº¦ã‚¢ã‚¯ã‚»ã‚¹ã«ã¯ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¿…è¦ã§ã™ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dc757c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9747d079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f96e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc64b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325529e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
